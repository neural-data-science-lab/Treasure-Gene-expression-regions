\documentclass[]{article}
\usepackage[left=3cm,right=3cm,top=1.5cm,bottom=2cm,includeheadfoot]{geometry} 
\usepackage{babel}
\usepackage{hyperref}
\usepackage{mwe}
\usepackage[markcase=noupper
]{scrlayer-scrpage}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{multirow}

% bibliography natbib
\usepackage{natbib}
\bibliographystyle{abbrvnat}
%\setcitestyle{authoryear, open={((},close={))}
\renewcommand{\cite}{\citep}


% configure headline

\ihead{Tilman Hinnerichs}
\ohead{Linking Connectivities and Gene Expression Patterns in Mice Brains}
\cfoot*{\pagemark}
%opening
\title{Linking Connectivities and Gene Expression Patterns in Mice Brains}
\author{Tilman Hinnerichs}
\date{}
\pagestyle{headings}

% Build subsubsubsection
\usepackage{titlesec}
\usepackage{todonotes}

%Definitions
\newtheorem{mydef}{Definition}
\newtheorem{example}{Example}
\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}
\newtheorem{proposition}{Proposition}

\newcommand{\name}{Treasure}

\newcommand{\HRule}[1]{\rule{\linewidth}{#1}}
\setcounter{tocdepth}{5}
\setcounter{secnumdepth}{5}

%-------------------------------------------------------------------------------
% TITLE PAGE
%-------------------------------------------------------------------------------

\begin{document}
	
\title{ \normalsize \textsc{Diploma thesis}
	\\ [2.0cm]
	\HRule{0.5pt} \\
	\LARGE \textbf{\uppercase{Linking Connectivities and Gene Expression Patterns in Mice Brains}
		\HRule{1pt} \\ [0.5cm]
		\normalsize September 30, 2021 \vspace*{5\baselineskip}}
	
	\date{Summer semester 2021}
	
	\author{
		Tilman Hinnerichs \\
		Matrikelnummer: 4643427 \\ 
		Technische Universität Dresden\vspace{1cm}\\
		Tutor: Dr. Nico Scherf\\
		MPI for CBS}}
\maketitle
\todo{proper title?}
\newpage
\begin{abstract}
	
\end{abstract}

\newpage

\tableofcontents

\newpage





\newpage

\section{Introduction}
\label{sec:introduction}
General thread for introduction and motivation:
\begin{itemize}
	\item Gene expression patterns are difficult to analyze in humans $\rightarrow$ take mouse as model organisms
	\item The brain is a multi-level system in which the high-level functions are generated by low-level genetic mechanisms. Thus, elucidating the relationship among multiple brain levels via correlative and predictive analytics is an important area in brain research. Currently, studies in multiple species have indicated that the spatiotemporal gene expression patterns are predictive of brain wiring. Specifically, results on the worm Caenorhabditis elegans have shown that the prediction of neuronal connectivity using gene expression signatures yielded statistically significant results.
	\item no in-depth analysis of mouse brain genetic patterns and their relation to different connectivity patterns has been made yet
	\item we analyze 
	
	\item studies have shown circadian patterns of gene expression in human brain and the disruption of those in depressive disorder \cite{li2013circadian}
	\item \cite{twine2011whole} show the importance of gene expression patterns, by linking gene expression abberation with increase in Alzheimer's disease
	
\end{itemize}

\subsection*{General Introduction of the Research Study}

\subsection*{Research problem or Questions with Sub-Questions}

\subsection*{Reasons or Needs for the Research Study/Motivation for my research}

\subsection*{Definition and explanation of Key Terminology}

\subsection*{Context of Research Study within th Greater Discipline}

\begin{itemize}
	\item Introduction to mouse brains as model organisms for insights into human brain
	\item Works on mouse brain in general and potential tasks
	\item works on gene expression in mouse brains
	\begin{itemize}
		\item traditional approaches
		\item importance of gene expression patterns in mouse brains
	\end{itemize}
	\item neural networks for this purpose
	\begin{itemize}
		\item how were 
	\end{itemize}
	\item gene expression for general tissue
	
\end{itemize}

\newpage
\section{Literature overview}
\label{sec:relatedwork}
\subsection{Gene expression prediction}

\begin{itemize}

	\item \cite{lee2020prediction} train classifiers using blood gene expression data in order to predict Alheimer's disease in Humans

	
\end{itemize}

\subsection{Finding spatial patterns in gene expression in mice brains}

\begin{itemize}
	\item Sparked by the \citet{MouseBrainAtlas}
	\item \cite{zapala2005adult} is among the earliest works, showing that local structures beared "transcriptional imprint" that coincide with the embryological origin of the examined regions. However, they only were able to identify up to 24 neural tissues. They further conclude that this may be important for functional collaboration within the adult mouse brain.
\end{itemize}
\begin{itemize}
	\item Have GCNs be applied before here?
	\item usage of ontologies?
	\begin{itemize}
		\item functional graph \cite{ValkShapingBrainStructure2020}
		\item structural ontology?
		\item developmental ontology
	\end{itemize}
\end{itemize}

\subsection*{How to deviate from \cite{Partel2020}}

\subsection{Approaches to dimensionality reduction and their application}
\begin{itemize}
	\item Brief Overview of theoretical Foundations Utilized in the study
\end{itemize}

\subsection{Structural and functional connectivity prediction}
\subsection*{Structural/Axonal connectivity}

\begin{itemize}
	\item \cite{fakhry2015high} predict axonal connectivity from gene expression patterns in mice brain with an accuracy of 93\%
	\item \cite{roberti2019exploiting} use transcriptomic information to anatomical connectivity patterns and gene expression of neurons using (shallow) neural networks. Yield a 85\% accuracy in prediction of unconnected and connected regions.
	
\end{itemize}

\begin{itemize}
	\item experimental setup from Allen Institute for axonal projection data
	\item paraphrase description of \glqq Technical tour: Explore the Allen Mouse Brain Connectivity Atlas\grqq{}
\end{itemize}



\subsection*{Functional connectivity}
\begin{itemize}
	\item \cite{whitfield2003gene} were one of the first to link transcriptomic data with behavior and hence functional patterns in individual honey bees back in 2003. The authors show that changes in the messenger RNA were connected to behavior.
	\item \cite{rankin2002gene} first developed the idea of combining behavioral analyses of \textit{Caenorhabditis elegans} with their genetics. Further, \cite{sun2021temporal} only recently described the distinct functional states and the corresponding distinct molecular states within the transcriptome. While honey bees and nematodes are rather simple model organisms, enabling both full transcriptomic analyses of the organisms, and their bearing and actions. However, "behavior" may be ambiguous and vague for such taxonomically distant animals, from the viewpoint of humans, and may only be linked to very basic meta-tasks such as basic routing, orientation and basic social interaction. 
	\item Why do we not directly investigate gene expression patterns in human brains?
	\begin{itemize}
		\item only few data points are given for the entirety of the human brain, while spatial decomposition and partitioning is crucially more complex. 
	\end{itemize}
	\item \cite{wang2022network} recently proposed a novel-network based method integrating molecular-based gene association networks such as protein-protein interaction networks with brain connectome data. They further link these gene expression patterns to four brain diseases, including Alzheimer’s disease, Parkinson’s disease, major depressive disorder and autism.
\end{itemize}
\begin{itemize}
	\item Where is data coming from? \cite{AIDAmri2019}
	\item How to calculate functional connectivity matrix $\rightarrow$ AIDAconnect (no paper yet? cite dataset?
	\item How to combine functional connectivity for multiple samples? 
	\item \cite{Zerbi2021}
\end{itemize}


\subsection*{Brief Overview of LIterature Reviewed, Discussed and applied}

\subsection*{Study Model and Process Aligning with literature reviewed}

\subsection*{Hypotheses and justifications tied to prior sections and statements}

\subsection*{The Scope of the study with theoretical assumptions and limitations}

\subsection*{To be searched}
\begin{itemize}
	\item read across citations of DeepMOCCA/\citet{takata_flexible_2021}
	\item find other papers on
	\begin{itemize}
		\item gene expression patterns within mouse brain and both possible hypothesis and tasks, and models over this
		\item gene knockout models and whether they can learn propagation of those?
		\item connection of FC and gene expression patterns and how to prove such interaction/correlation?
		\item possible gene knockout targets within mouse brain and possible structural influences
	\end{itemize}
\end{itemize}

\subsection*{To be sorted somewhere}
\begin{itemize}
	\item Variability and different interpretations of different graph convolutional neural filters \cite{GCNConv, GENConv2020, SAGEConv} etc.
	\item Guilt by association over gene networks \cite{Oliver2000, Gillis2012}
	\item protein function prediction from PPI networks \cite{Vazquez2003}
	\item DeepGOPlus for feature generation \cite{DeepGoPlus}
	\item discussion of DeepMocca by Sara \cite{DeepMocca2021}
	\item discussion of different PPI network databases \cite{STRINGv10}
	\item discussion of potential databases associating gene expression data with their spatial distribution \cite{hawrylycz_digital_2011}
	\item discussion of best neural learning/graph convolutional methods \cite{Pytorch, PytorchGeometric}
	\item how to handle highly imbalanced data, metrics, preprocessing, sampling, modification of loss function \cite{Jeni2013} and optimization over them (with Adam\cite{Adam2014})
	\item maybe introduction of PhenomeNET for MP/GO for more sophisticated protein representation \cite{PhenomeNET2011, GOoriginal2000, GOrecent2020, MP2009} and derive features from DL2vec \cite{DL2vec2020, Word2vec2013}
	\item evaluation of \glqq Using ontology embeddings for structural inductive bias in gene expression data analysis\grqq{}\cite{Trebacz2020}
	\item take some ideas from \citet{Zitnik2017} with title \glqq Predicting multicellular function through multi-layer tissue networks\grqq{}. (OhmNet)
	\item potentially group results based on InterPro\cite{Interpro2020} families eventually
	\item RayTune\cite{liaw2018tune} for automated hyperparameter tuning
\end{itemize}

\subsection*{Spatial patterns of gene expression}

Data discussion, hypotheses and traditional approaches:
\begin{itemize}
	\item \cite{noauthor_clustering_nodate}
	\item Possible effects of rabies virus on gene expression\cite{prosniak_effect_2001} for potential knockout targets
	
	\item Review paper on regional variation in gene expression in mouse brain \cite{pavlidis_analysis_2001}
\end{itemize}

Modern approaches on learning from gene expression patterns in mouse brain:
\begin{itemize}
	\item Deep learning methods for capturing spatiality w.r.t. gene expression withing the brain \cite{zeng_deep_2015}
	\item R package for simulating gene expression from graph structures over general biological pathways \cite{kelly_graphsim_2020} \todo[inline]{Read this}
\end{itemize}



\newpage
\section{Materials and methods}
\label{sec:methods}
In this study, we utilized and incorporated various approaches from other works and applied them to diverse datasets. The following section will give a brief overview over all modules of the proposed model, while the combined method will be presented and described in the results section (Section \ref{sec:results}).
\subsection*{Introduction and general description, study method and study design}
\subsection{Problem description}
Here we give a brief introduction to each of the three tackled issues and further summarize data properties, challenges and goals of each problem. 
\subsubsection{Spatial gene expression prediction}
Firstly, the issue of gene expression prediction 

\subsubsection{Dimensionality reduction in mice brains}
\begin{itemize}
	\item 
\end{itemize}

\subsubsection{Structural and functional connectivity prediction}
\begin{itemize}
	\item 
\end{itemize}


\subsection*{Assumptions of study method and study design with implied }

\subsection{Datasets}
\subsection*{in-depth description of the study design/datasets used and motivation why they were used for these experiments}
\subsection*{Explanation of Sample used in the study}
\begin{itemize}
	\item show distribution (histo, mean, median, boxplot?) of expression densities see `get\_ge\_structure\_mat`

	\item how to normalize expression intensity (see discussion in DeepMOCCA paper, Sara Alghamdi), as there are regions with much more activity than others (e.g. bone narrow vs. bone boarder); thresholds for intensity varies across genes
	
	\begin{itemize}
		\item over all intensities $\rightarrow$
		\item per structure $\rightarrow$  
		\item per gene $\rightarrow$ 
	\end{itemize}
\end{itemize}

\begin{itemize}
	\item why were these datasets used and not others?
	\item How did we achieve the matching?
	\item what are premises of the dataset?
	
	\item transfer learning working for other structure/regions
	\item dataset: Allen Mouse brain atlas vs. 
	\begin{itemize}
		\item \href{https://www.har.mrc.ac.uk/harwell-news/phenoview-new-tool-compare-impc-data/}{phenoview impc data}
		
		\item \href{https://www.mousephenotype.org/}{mousephenotype}
		
		\item \href{http://www.informatics.jax.org/expression.shtml}{HPO/MP project expression data}
	\end{itemize}
\end{itemize}
\begin{itemize}
	\item Allen mouse brain atlas \cite{MouseBrainAtlas}
	\begin{itemize}
		\item discussion on different normalization schemes
	\end{itemize}
	\item STRING for PPI network and how we chose suitable interactions \cite{STRINGv10}
\end{itemize}

Four graphs were used in this study:
\begin{itemize}
	\item Protein-protein interaction graph from STRING
	\item structure hierarchy/ontology from \cite{MouseBrainAtlas}
	\item structural connectivity data from (Mouse Projection data)
	\item functional connectivity data from \cite{AIDAmri2019}
\end{itemize}

\subsection{Model}
\subsection*{Explanation of Measurement, Definitions, Indexes, Reliabililty and Validity of study method and study design}
\subsection*{Description of Analytical Tehcniques to be Applied and justification for them}

\subsection*{Reliability and validity of internal/external design and related subtypes}

\subsubsection{Feature generation}

Data preparation for regression task
\begin{itemize}
	\item unbalanced data for prediction task
\end{itemize}

\subsubsection{Graph convolutional neural layers}

We include these molecular and ontology-based sub-models within a
graph neural network (GNN) \cite{GCNConv}. The graph underlying the GNN is
based on the protein--protein interaction (PPI) graph. The PPI dataset
is represented by a graph $G=(V,E)$, where each protein is represented
by a vertex $v\in V$, and each edge $e\in E\subseteq V\times V$
represents an interaction between two proteins. Additionally, we
introduce a mapping $x:V\rightarrow\mathbb{R}^{d}$ projecting each
vertex $v$ to its node feature $x_v := x(v)$, where $d$ denotes the
dimensionality of the node features.

% As described before, graph convolution has shown significant
% performance increase in a variety of tasks. While there are various
% methods out there we will only introduce the most basic one here. 
A graph convolutional layer \cite{GCNConv} consists of a learnable
weight matrix followed by an aggregation step, formalized by
\begin{equation}
	\mathbf{X}^{\prime} = \mathbf{\hat{D}}^{-1/2} \mathbf{\hat{A}}
	\mathbf{\hat{D}}^{-1/2} \mathbf{X} \mathbf{\Theta}
\end{equation}
where for a given graph $G=(V,E)$, $\hat{A} = A + I$ denotes the
adjacency matrix with added self-loops for each vertex, $D$ is
described by $\hat{D}_{ii} = \sum_{j=0} \hat{A}_{ij}$, a diagonal
matrix displaying the degree of each node, and $\Theta$ denotes the
learnable weight matrix. Added self-loops enforce that each node
representation is directly dependent on its own preceding one. The
number of graph convolutional layers stacked equals the radius of
relevant nodes for each vertex within the graph.

The update rule for each node is given by a message passing scheme
formalized by
\begin{equation}
	\mathbf{x}^{\prime}_i = \mathbf{\Theta} \sum^{N}_{j}
	\frac{1}{\sqrt{\hat{d}_j \hat{d}_i}} \mathbf{x}_j
\end{equation}
where both $\hat{d}_i, \hat{d}_j$ are dependent on the edge weights
$e_{ij}$ of the graph. With simple, single-valued edge weights such as
$e_{ij}=1 \text{ }\forall (i,j)\in E$, all $\hat{d}_i$ reduce to
$d_i$, i.e., the degree of each vertex $i$. We denote this type of
graph convolutional neural layers with \textsc{GCNConv}.

While in this initial formulation of a GCNConv the node-wise update
step is defined by the sum over all neighboring node representations,
we can alter this formulation to other message passing schemes.  We
can rearrange the order of activation function $\sigma$, aggregation
$\mathrm{AGG}$, and linear neural layer $\mathrm{MLP}$ with this
formulation as proposed by \cite{GENConv2020}:
\begin{equation}
	\mathbf{x}_i^{\prime} = \mathrm{MLP} \left( \mathbf{x}_i +
	\mathrm{AGG} \left( \left\{
	\mathrm{\sigma} \left( \mathbf{x}_j + \mathbf{e_{ji}} \right) +\epsilon
	: j \in \mathcal{N}(i) \right\} \right)
	\right)
\end{equation}
where we only consider
$\sigma \in \{\mathrm{ReLU}, \mathrm{LeakyReLU}\}$. We denote this
generalized layer type as \textsc{GENConv} following the notation of
PyTorch Geometric \cite{PytorchGeometric}.  While the reordering is
mainly important for numerical stability, this alteration also addresses
the vanishing gradient problem for deeper convolutional networks
\cite{GENConv2020}. Additionally, we can also generalize the
aggregation function to allow different weighting functions such as
learnable $\mathrm{SoftMax}$ or $\mathrm{Power}$ for the incoming
signals for each vertex, substituting the averaging step in
\textsc{GCNConv}. Hence, while \textsc{GCNConv} suffers from both
vanishing gradients and signal fading for large scale and highly
connected graphs, each propagation step in \textsc{GENConv} emphasizes
signals with values close to $0$ and $1$. The same convolutional
filter and weight matrix are applied to and learned for all nodes
simultaneously. % , and the resulting information\todo{Which information?
% Specify} hold no information on their own connectivity.
We further employ another mechanism to avoid redundancy and fading
signals in stacked graph convolutional networks, using residual
connections and a normalization scheme \cite{DeepGCN2019}
	\cite{GENConv2020} as shown in Supplementary 3.  The residual
blocks are reusable and can be stacked multiple times.

\begin{itemize}
	\item what is GATConv?
	\item what is KerGNN and what is its idea?
	\item add some sentences to the section above
\end{itemize}

\subsubsection{Dimensionality reduction techniques}
\paragraph{Principal component analysis}

\paragraph{tSNE}

\paragraph{UMAP}

\paragraph{Parametric UMAP}

\subsubsection{Combined prediction model}

\subsubsection{Hyperparameter tuning}

\subsection{Evaluation and metrics}
\begin{itemize}
	\item self-build metric for evaluation
\end{itemize}


\newpage
\section{Results}
\label{sec:results}
\subsection{Gene expression prediction}

\begin{itemize}
	\item We originally started from the per section prediction in order to paste its performance and results to other "related" structures within in the mouse brain. We propose multiple ideas \dots. As mentioned we used three different feature types in this study. \dots (molecular features, phenotypical features, pure taxonomic features (InterPro embedding))) \dots Due to the poor performance of the predictor with all three used feature types, we abandoned these plane
	\begin{itemize}
		\item 
	\end{itemize}
	\item structure specific features?
	\begin{itemize}
		\item structural ontology / closeness
		\item developmental hierarchy of tissue
	\end{itemize}
\end{itemize}

Our model also allows us to test different ways of representing omics data. We
tested different ways to normalize values assigned to genes as these normalizations
convey different biological information; in the matrix of values assigned to genes from
cancer samples, we can normalize values across the entire matrix, across each row
(cancer sample), or across each column (gene). While a global normalization is more
common, row-based normalization allows us to highlight values that are significantly
higher or lower within one sample (e.g., which genes are expressed at high or low levels within a single sample), and column-based normalization allows us to highlight values
assigned to a particular gene that are significantly higher or lower within one sample
(e.g., whether a gene is expressed at higher or lower levels within one sample compared
to all others). We find that column-based normalization performs better than row-based
normalization, while the global normalization approach performs close to random. The
best results are achieved when combining both row- and column-based normalization
(Supplementary Table 2).	

\subsection{Dimensionality reduction and its combination with different graphs structures}

\begin{itemize}
	\item plot for showing validity of embeddings: K-means colour with respect to cluster 
	\item plot colour parent structure all similar
\end{itemize}

\subsection{On the linkage of connectivities and gene expression patterns}

\subsection*{Brief Overview of Material}
\subsection*{Findings (Results) of the Method of Study and Any Unplanned or Unexpected Situations that Occurred}
\subsection*{Brief Descriptive Analysis
Reliability and Validity of the Analysis}
\subsection*{Explanation of the Hypothesis and Precise and Exact Data (Do Not Give Your Opinion)}


\newpage
\section{Discussion}
\label{sec:discussion}
\subsection*{Brief Overview of Material}
\subsection*{Full Discussion of Findings (Results) and Implications}
\subsection*{Full Discussion of Research Analysis of Findings}
\subsection*{Full Discussion of Hypothesis and of Findings}
\subsection*{Post Analysis and Implications of Hypothesis and of Findings}



\newpage
\section{Conclusion}
\label{sec:conclusion}

\subsection*{Summary of Academic Study}
\subsection*{Reference to Literature Review}
\subsection*{Implications of Academic Study}
\subsection*{Limitations of the Theory or Method of Research}
\subsection*{Recommendations or Suggestions of Future Academic Study}

\begin{itemize}
	\item gene expression patterns within mouse brain and both possible hypothesis and tasks, and models over this
	\item gene knockout models and whether they can learn propagation of those?
	\item connection of FC and gene expression patterns and how to prove such interaction/correlation?
	\item possible gene knockout targets within mouse brain and possible structural influences
\end{itemize}


\newpage

\bibliography{citations}

\end{document}